[ai]
provider = "claude"
api_key = "sk-..."
model = "claude-3-5-haiku-latest"
max_tokens = 5000

#[ai]
#provider = "ollama"
#model =  "llama3.2:latest"
#model = "phi3:mini"
#model = "phi4:latest"
#model = "deepseek-r1:7b"
#model = "deepseek-r1:8b"
#host = "http://localhost:11434"

#[ai]
#provider = "openai"
#base_url = "https://api.deepseek.com"
#api_key = "..."
#temperature = 0.0
#max_tokens = 1024

#[ai]
#provider = "gemini"
#api_key = "..."
#model = "gemini-2.0-flash"  # "models/gemini-2.0-flash-lite-preview-02-05"


[search]
initial_spread = 10     # How many random tries to make at depth=0.
random_spread = 2       # How many random tries to make before selecting the best move.
max_depth = 30          # Maximum depth of the search tree.
max_temperature = 1     # Tries random temperature, up to this value.
max_minutes = 60        # Stop after 60 minutes of search.
                        # Some models perform better at lower temps, in general
                        # Higher temperature = more exploration.
cache = true            # Caches AI responses to a local file to speed up re-runs and
                        # save money.